{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "使用我个人的账户试试"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercise 2: Creating Redshift Cluster using the AWS python SDK \n",
    "## An example of Infrastructure-as-code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import boto3\n",
    "import json"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "toc-hr-collapsed": true
   },
   "source": [
    "## STEP 0: (Prerequisite) Save the AWS Access key\n",
    "\n",
    "### 1. Create a new IAM user\n",
    "IAM service is a global service, meaning newly created IAM users are not restricted to a specific region by default.\n",
    "- Go to [AWS IAM service](https://console.aws.amazon.com/iam/home#/users) and click on the \"**Add user**\" button to create a new IAM user in your AWS account. \n",
    "- Choose a name of your choice. \n",
    "- Select \"*Programmatic access*\" as the access type. Click Next. \n",
    "- Choose the *Attach existing policies directly* tab, and select the \"**AdministratorAccess**\". Click Next. \n",
    "- Skip adding any tags. Click Next. \n",
    "- Review and create the user. It will show you a pair of access key ID and secret.\n",
    "- Take note of the pair of access key ID and secret. This pair is collectively known as **Access key**. \n",
    "\n",
    "<center>\n",
    "<img style=\"float: center;height:300px;\" src=\"images/AWS_IAM_1.png\"><br><br>\n",
    "Snapshot of a pair of an Access key\n",
    "</center>\n",
    "\n",
    "### <font color='red'>2. Save the access key and secret</font>\n",
    "Edit the file `dwh.cfg` in the same folder as this notebook and save the access key and secret against the following variables:\n",
    "```bash\n",
    "KEY= <YOUR_AWS_KEY>\n",
    "SECRET= <YOUR_AWS_SECRET>\n",
    "```\n",
    "    \n",
    "For example:\n",
    "```bash\n",
    "KEY=6JW3ATLQ34PH3AKI\n",
    "SECRET=wnoBHA+qUBFgwCRHJqgqrLU0i\n",
    "```\n",
    "\n",
    "### 3. Troubleshoot\n",
    "If your keys are not working, such as getting an `InvalidAccessKeyId` error, then you cannot retrieve them again. You have either of the following two options:\n",
    "\n",
    "1. **Option 1 - Create a new pair of access keys for the existing user**\n",
    "\n",
    " - Go to the [IAM dashboard](https://console.aws.amazon.com/iam/home) and view the details of the existing (Admin) user. \n",
    "\n",
    " - Select on the **Security credentials** tab, and click the **Create access key** button. It will generate a new pair of access key ID and secret.\n",
    "\n",
    " - Save the new access key ID and secret in your `dwh.cfg` file\n",
    "\n",
    "\n",
    "<center>\n",
    "<img style=\"float: center;height:450px;\" src=\"images/AWS_IAM_2.png\"><br><br>\n",
    "Snapshot of creating a new Access keys for the existing user\n",
    "</center>\n",
    "\n",
    "2. **Option 2 - Create a new IAM user with Admin access** - Refer to the instructions at the top. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load DWH Params from a file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Param</th>\n",
       "      <th>Value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>DWH_CLUSTER_TYPE</td>\n",
       "      <td>multi-node</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>DWH_NUM_NODES</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>DWH_NODE_TYPE</td>\n",
       "      <td>dc2.large</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>DWH_CLUSTER_IDENTIFIER</td>\n",
       "      <td>dwhClusterTry4extra</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>DWH_DB</td>\n",
       "      <td>dwh</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>DWH_DB_USER</td>\n",
       "      <td>dwhuser</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>DWH_DB_PASSWORD</td>\n",
       "      <td>Passw0rd</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>DWH_PORT</td>\n",
       "      <td>5439</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>DWH_IAM_ROLE_NAME</td>\n",
       "      <td>dwhRole</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    Param                Value\n",
       "0        DWH_CLUSTER_TYPE           multi-node\n",
       "1           DWH_NUM_NODES                    8\n",
       "2           DWH_NODE_TYPE            dc2.large\n",
       "3  DWH_CLUSTER_IDENTIFIER  dwhClusterTry4extra\n",
       "4                  DWH_DB                  dwh\n",
       "5             DWH_DB_USER              dwhuser\n",
       "6         DWH_DB_PASSWORD             Passw0rd\n",
       "7                DWH_PORT                 5439\n",
       "8       DWH_IAM_ROLE_NAME              dwhRole"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import configparser\n",
    "config = configparser.ConfigParser()\n",
    "config.read_file(open('dwh-4.cfg'))\n",
    "\n",
    "KEY                    = config.get('AWS','KEY')\n",
    "SECRET                 = config.get('AWS','SECRET')\n",
    "\n",
    "DWH_CLUSTER_TYPE       = config.get(\"DWH\",\"DWH_CLUSTER_TYPE\")\n",
    "DWH_NUM_NODES          = config.get(\"DWH\",\"DWH_NUM_NODES\")\n",
    "DWH_NODE_TYPE          = config.get(\"DWH\",\"DWH_NODE_TYPE\")\n",
    "\n",
    "DWH_CLUSTER_IDENTIFIER = config.get(\"DWH\",\"DWH_CLUSTER_IDENTIFIER\")\n",
    "DWH_DB                 = config.get(\"DWH\",\"DWH_DB\")\n",
    "DWH_DB_USER            = config.get(\"DWH\",\"DWH_DB_USER\")\n",
    "DWH_DB_PASSWORD        = config.get(\"DWH\",\"DWH_DB_PASSWORD\")\n",
    "DWH_PORT               = config.get(\"DWH\",\"DWH_PORT\")\n",
    "\n",
    "DWH_IAM_ROLE_NAME      = config.get(\"DWH\", \"DWH_IAM_ROLE_NAME\")\n",
    "\n",
    "(DWH_DB_USER, DWH_DB_PASSWORD, DWH_DB)\n",
    "\n",
    "pd.DataFrame({\"Param\":\n",
    "                  [\"DWH_CLUSTER_TYPE\", \"DWH_NUM_NODES\", \"DWH_NODE_TYPE\", \"DWH_CLUSTER_IDENTIFIER\", \"DWH_DB\", \"DWH_DB_USER\", \"DWH_DB_PASSWORD\", \"DWH_PORT\", \"DWH_IAM_ROLE_NAME\"],\n",
    "              \"Value\":\n",
    "                  [DWH_CLUSTER_TYPE, DWH_NUM_NODES, DWH_NODE_TYPE, DWH_CLUSTER_IDENTIFIER, DWH_DB, DWH_DB_USER, DWH_DB_PASSWORD, DWH_PORT, DWH_IAM_ROLE_NAME]\n",
    "             })"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create clients and resources for IAM, EC2, S3, and Redshift\n",
    "\n",
    "To interact with EC2 and S3, utilize `boto3.resource`; for IAM and Redshift, use `boto3.client`. If you require additional details on boto3, refer to the [boto3 documentation](https://boto3.amazonaws.com/v1/documentation/api/latest/index.html).\n",
    "\n",
    "**Note**: We create clients and resources in the **us-west-2** region. Choose the same region in your AWS Web Console to see these resources."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import boto3\n",
    "\n",
    "ec2 = boto3.resource('ec2',\n",
    "                       region_name=\"us-west-2\",\n",
    "                       aws_access_key_id=KEY,\n",
    "                       aws_secret_access_key=SECRET\n",
    "                    )\n",
    "\n",
    "s3 = boto3.resource('s3',\n",
    "                       region_name=\"us-west-2\",\n",
    "                       aws_access_key_id=KEY,\n",
    "                       aws_secret_access_key=SECRET\n",
    "                   )\n",
    "\n",
    "iam = boto3.client('iam',aws_access_key_id=KEY,\n",
    "                     aws_secret_access_key=SECRET,\n",
    "                     region_name='us-west-2'\n",
    "                  )\n",
    "\n",
    "redshift = boto3.client('redshift',\n",
    "                       region_name=\"us-west-2\",\n",
    "                       aws_access_key_id=KEY,\n",
    "                       aws_secret_access_key=SECRET\n",
    "                       )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Check out the sample data sources on S3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "s3.ObjectSummary(bucket_name='awssampledbuswest2', key='ssbgz/')\n",
      "s3.ObjectSummary(bucket_name='awssampledbuswest2', key='ssbgz/customer0002_part_00.gz')\n",
      "s3.ObjectSummary(bucket_name='awssampledbuswest2', key='ssbgz/dwdate.tbl.gz')\n",
      "s3.ObjectSummary(bucket_name='awssampledbuswest2', key='ssbgz/lineorder0000_part_00.gz')\n",
      "s3.ObjectSummary(bucket_name='awssampledbuswest2', key='ssbgz/lineorder0001_part_00.gz')\n",
      "s3.ObjectSummary(bucket_name='awssampledbuswest2', key='ssbgz/lineorder0002_part_00.gz')\n",
      "s3.ObjectSummary(bucket_name='awssampledbuswest2', key='ssbgz/lineorder0003_part_00.gz')\n",
      "s3.ObjectSummary(bucket_name='awssampledbuswest2', key='ssbgz/lineorder0004_part_00.gz')\n",
      "s3.ObjectSummary(bucket_name='awssampledbuswest2', key='ssbgz/lineorder0005_part_00.gz')\n",
      "s3.ObjectSummary(bucket_name='awssampledbuswest2', key='ssbgz/lineorder0006_part_00.gz')\n",
      "s3.ObjectSummary(bucket_name='awssampledbuswest2', key='ssbgz/lineorder0007_part_00.gz')\n",
      "s3.ObjectSummary(bucket_name='awssampledbuswest2', key='ssbgz/part0000_part_00.gz')\n",
      "s3.ObjectSummary(bucket_name='awssampledbuswest2', key='ssbgz/part0001_part_00.gz')\n",
      "s3.ObjectSummary(bucket_name='awssampledbuswest2', key='ssbgz/part0002_part_00.gz')\n",
      "s3.ObjectSummary(bucket_name='awssampledbuswest2', key='ssbgz/part0003_part_00.gz')\n",
      "s3.ObjectSummary(bucket_name='awssampledbuswest2', key='ssbgz/supplier.tbl_0000_part_00.gz')\n",
      "s3.ObjectSummary(bucket_name='awssampledbuswest2', key='ssbgz/supplier0001_part_00.gz')\n",
      "s3.ObjectSummary(bucket_name='awssampledbuswest2', key='ssbgz/supplier0002_part_00.gz')\n",
      "s3.ObjectSummary(bucket_name='awssampledbuswest2', key='ssbgz/supplier0003_part_00.gz')\n"
     ]
    }
   ],
   "source": [
    "sampleDbBucket =  s3.Bucket(\"awssampledbuswest2\")\n",
    "for obj in sampleDbBucket.objects.filter(Prefix=\"ssbgz\"):\n",
    "    print(obj)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "s3.ObjectSummary(bucket_name='awssampledbuswest2', key='load/')\n",
      "s3.ObjectSummary(bucket_name='awssampledbuswest2', key='load/customer-fw-manifest')\n",
      "s3.ObjectSummary(bucket_name='awssampledbuswest2', key='load/customer-fw.tbl-000')\n",
      "s3.ObjectSummary(bucket_name='awssampledbuswest2', key='load/customer-fw.tbl-000.bak')\n",
      "s3.ObjectSummary(bucket_name='awssampledbuswest2', key='load/customer-fw.tbl-001')\n",
      "s3.ObjectSummary(bucket_name='awssampledbuswest2', key='load/customer-fw.tbl-002')\n",
      "s3.ObjectSummary(bucket_name='awssampledbuswest2', key='load/customer-fw.tbl-003')\n",
      "s3.ObjectSummary(bucket_name='awssampledbuswest2', key='load/customer-fw.tbl-004')\n",
      "s3.ObjectSummary(bucket_name='awssampledbuswest2', key='load/customer-fw.tbl-005')\n",
      "s3.ObjectSummary(bucket_name='awssampledbuswest2', key='load/customer-fw.tbl-006')\n",
      "s3.ObjectSummary(bucket_name='awssampledbuswest2', key='load/customer-fw.tbl-007')\n",
      "s3.ObjectSummary(bucket_name='awssampledbuswest2', key='load/customer-fw.tbl.log')\n",
      "s3.ObjectSummary(bucket_name='awssampledbuswest2', key='load/dwdate-tab.tbl-000')\n",
      "s3.ObjectSummary(bucket_name='awssampledbuswest2', key='load/dwdate-tab.tbl-001')\n",
      "s3.ObjectSummary(bucket_name='awssampledbuswest2', key='load/dwdate-tab.tbl-002')\n",
      "s3.ObjectSummary(bucket_name='awssampledbuswest2', key='load/dwdate-tab.tbl-003')\n",
      "s3.ObjectSummary(bucket_name='awssampledbuswest2', key='load/dwdate-tab.tbl-004')\n",
      "s3.ObjectSummary(bucket_name='awssampledbuswest2', key='load/dwdate-tab.tbl-005')\n",
      "s3.ObjectSummary(bucket_name='awssampledbuswest2', key='load/dwdate-tab.tbl-006')\n",
      "s3.ObjectSummary(bucket_name='awssampledbuswest2', key='load/dwdate-tab.tbl-007')\n",
      "s3.ObjectSummary(bucket_name='awssampledbuswest2', key='load/lo/')\n",
      "s3.ObjectSummary(bucket_name='awssampledbuswest2', key='load/lo/lineorder-multi.tbl0000_part_00.gz')\n",
      "s3.ObjectSummary(bucket_name='awssampledbuswest2', key='nested_example/')\n",
      "s3.ObjectSummary(bucket_name='awssampledbuswest2', key='nested_example/customers/')\n",
      "s3.ObjectSummary(bucket_name='awssampledbuswest2', key='nested_example/customers/customer_file1')\n",
      "s3.ObjectSummary(bucket_name='awssampledbuswest2', key='resize/')\n",
      "s3.ObjectSummary(bucket_name='awssampledbuswest2', key='resize/etl_category_pipe.txt')\n",
      "s3.ObjectSummary(bucket_name='awssampledbuswest2', key='resize/etl_date_pipe.txt')\n",
      "s3.ObjectSummary(bucket_name='awssampledbuswest2', key='resize/etl_events_pipe.txt')\n",
      "s3.ObjectSummary(bucket_name='awssampledbuswest2', key='resize/etl_venue_pipe.txt')\n",
      "s3.ObjectSummary(bucket_name='awssampledbuswest2', key='resize/listings_pipe_1.txt')\n",
      "s3.ObjectSummary(bucket_name='awssampledbuswest2', key='restorelineorder/')\n",
      "s3.ObjectSummary(bucket_name='awssampledbuswest2', key='restorelineorder/lineorder0000_part_00.gz')\n",
      "s3.ObjectSummary(bucket_name='awssampledbuswest2', key='restorelineorder/lineorder0001_part_00.gz')\n",
      "s3.ObjectSummary(bucket_name='awssampledbuswest2', key='restorelineorder/lineorder0002_part_00.gz')\n",
      "s3.ObjectSummary(bucket_name='awssampledbuswest2', key='restorelineorder/lineorder0003_part_00.gz')\n",
      "s3.ObjectSummary(bucket_name='awssampledbuswest2', key='restorelineorder/lineorder0004_part_00.gz')\n",
      "s3.ObjectSummary(bucket_name='awssampledbuswest2', key='restorelineorder/lineorder0005_part_00.gz')\n",
      "s3.ObjectSummary(bucket_name='awssampledbuswest2', key='restorelineorder/lineorder0006_part_00.gz')\n",
      "s3.ObjectSummary(bucket_name='awssampledbuswest2', key='restorelineorder/lineorder0007_part_00.gz')\n",
      "s3.ObjectSummary(bucket_name='awssampledbuswest2', key='restorelineorder/lineorder0008_part_00.gz')\n",
      "s3.ObjectSummary(bucket_name='awssampledbuswest2', key='restorelineorder/lineorder0009_part_00.gz')\n",
      "s3.ObjectSummary(bucket_name='awssampledbuswest2', key='restorelineorder/lineorder0010_part_00.gz')\n",
      "s3.ObjectSummary(bucket_name='awssampledbuswest2', key='restorelineorder/lineorder0011_part_00.gz')\n",
      "s3.ObjectSummary(bucket_name='awssampledbuswest2', key='restorelineorder/lineorder0012_part_00.gz')\n",
      "s3.ObjectSummary(bucket_name='awssampledbuswest2', key='restorelineorder/lineorder0013_part_00.gz')\n",
      "s3.ObjectSummary(bucket_name='awssampledbuswest2', key='restorelineorder/lineorder0014_part_00.gz')\n",
      "s3.ObjectSummary(bucket_name='awssampledbuswest2', key='restorelineorder/lineorder0015_part_00.gz')\n",
      "s3.ObjectSummary(bucket_name='awssampledbuswest2', key='restorelineorder/results.txt')\n",
      "s3.ObjectSummary(bucket_name='awssampledbuswest2', key='ssbgz/')\n",
      "s3.ObjectSummary(bucket_name='awssampledbuswest2', key='ssbgz/customer0002_part_00.gz')\n",
      "s3.ObjectSummary(bucket_name='awssampledbuswest2', key='ssbgz/dwdate.tbl.gz')\n",
      "s3.ObjectSummary(bucket_name='awssampledbuswest2', key='ssbgz/lineorder0000_part_00.gz')\n",
      "s3.ObjectSummary(bucket_name='awssampledbuswest2', key='ssbgz/lineorder0001_part_00.gz')\n",
      "s3.ObjectSummary(bucket_name='awssampledbuswest2', key='ssbgz/lineorder0002_part_00.gz')\n",
      "s3.ObjectSummary(bucket_name='awssampledbuswest2', key='ssbgz/lineorder0003_part_00.gz')\n",
      "s3.ObjectSummary(bucket_name='awssampledbuswest2', key='ssbgz/lineorder0004_part_00.gz')\n",
      "s3.ObjectSummary(bucket_name='awssampledbuswest2', key='ssbgz/lineorder0005_part_00.gz')\n",
      "s3.ObjectSummary(bucket_name='awssampledbuswest2', key='ssbgz/lineorder0006_part_00.gz')\n",
      "s3.ObjectSummary(bucket_name='awssampledbuswest2', key='ssbgz/lineorder0007_part_00.gz')\n",
      "s3.ObjectSummary(bucket_name='awssampledbuswest2', key='ssbgz/part0000_part_00.gz')\n",
      "s3.ObjectSummary(bucket_name='awssampledbuswest2', key='ssbgz/part0001_part_00.gz')\n",
      "s3.ObjectSummary(bucket_name='awssampledbuswest2', key='ssbgz/part0002_part_00.gz')\n",
      "s3.ObjectSummary(bucket_name='awssampledbuswest2', key='ssbgz/part0003_part_00.gz')\n",
      "s3.ObjectSummary(bucket_name='awssampledbuswest2', key='ssbgz/supplier.tbl_0000_part_00.gz')\n",
      "s3.ObjectSummary(bucket_name='awssampledbuswest2', key='ssbgz/supplier0001_part_00.gz')\n",
      "s3.ObjectSummary(bucket_name='awssampledbuswest2', key='ssbgz/supplier0002_part_00.gz')\n",
      "s3.ObjectSummary(bucket_name='awssampledbuswest2', key='ssbgz/supplier0003_part_00.gz')\n",
      "s3.ObjectSummary(bucket_name='awssampledbuswest2', key='tickit/')\n",
      "s3.ObjectSummary(bucket_name='awssampledbuswest2', key='tickit/allevents_pipe.txt')\n",
      "s3.ObjectSummary(bucket_name='awssampledbuswest2', key='tickit/allusers_pipe.txt')\n",
      "s3.ObjectSummary(bucket_name='awssampledbuswest2', key='tickit/category_pipe.txt')\n",
      "s3.ObjectSummary(bucket_name='awssampledbuswest2', key='tickit/date2008_pipe.txt')\n",
      "s3.ObjectSummary(bucket_name='awssampledbuswest2', key='tickit/listings_pipe.txt')\n",
      "s3.ObjectSummary(bucket_name='awssampledbuswest2', key='tickit/sales_tab.txt')\n",
      "s3.ObjectSummary(bucket_name='awssampledbuswest2', key='tickit/spectrum/')\n",
      "s3.ObjectSummary(bucket_name='awssampledbuswest2', key='tickit/spectrum/category/category_pipe.txt')\n",
      "s3.ObjectSummary(bucket_name='awssampledbuswest2', key='tickit/spectrum/date/date2008_pipe.txt')\n",
      "s3.ObjectSummary(bucket_name='awssampledbuswest2', key='tickit/spectrum/event/allevents_pipe.txt')\n",
      "s3.ObjectSummary(bucket_name='awssampledbuswest2', key='tickit/spectrum/listing/listings_pipe.txt')\n",
      "s3.ObjectSummary(bucket_name='awssampledbuswest2', key='tickit/spectrum/sales/')\n",
      "s3.ObjectSummary(bucket_name='awssampledbuswest2', key='tickit/spectrum/sales/sales_ts.000')\n",
      "s3.ObjectSummary(bucket_name='awssampledbuswest2', key='tickit/spectrum/sales_partition/saledate=2008-01/0000_part_00')\n",
      "s3.ObjectSummary(bucket_name='awssampledbuswest2', key='tickit/spectrum/sales_partition/saledate=2008-01/0001_part_00')\n",
      "s3.ObjectSummary(bucket_name='awssampledbuswest2', key='tickit/spectrum/sales_partition/saledate=2008-01/0002_part_00')\n",
      "s3.ObjectSummary(bucket_name='awssampledbuswest2', key='tickit/spectrum/sales_partition/saledate=2008-01/0003_part_00')\n",
      "s3.ObjectSummary(bucket_name='awssampledbuswest2', key='tickit/spectrum/sales_partition/saledate=2008-01/0004_part_00')\n",
      "s3.ObjectSummary(bucket_name='awssampledbuswest2', key='tickit/spectrum/sales_partition/saledate=2008-01/0005_part_00')\n",
      "s3.ObjectSummary(bucket_name='awssampledbuswest2', key='tickit/spectrum/sales_partition/saledate=2008-02/0000_part_00')\n",
      "s3.ObjectSummary(bucket_name='awssampledbuswest2', key='tickit/spectrum/sales_partition/saledate=2008-02/0001_part_00')\n",
      "s3.ObjectSummary(bucket_name='awssampledbuswest2', key='tickit/spectrum/sales_partition/saledate=2008-02/0002_part_00')\n",
      "s3.ObjectSummary(bucket_name='awssampledbuswest2', key='tickit/spectrum/sales_partition/saledate=2008-02/0003_part_00')\n",
      "s3.ObjectSummary(bucket_name='awssampledbuswest2', key='tickit/spectrum/sales_partition/saledate=2008-02/0004_part_00')\n",
      "s3.ObjectSummary(bucket_name='awssampledbuswest2', key='tickit/spectrum/sales_partition/saledate=2008-02/0005_part_00')\n",
      "s3.ObjectSummary(bucket_name='awssampledbuswest2', key='tickit/spectrum/sales_partition/saledate=2008-03/0000_part_00')\n",
      "s3.ObjectSummary(bucket_name='awssampledbuswest2', key='tickit/spectrum/sales_partition/saledate=2008-03/0001_part_00')\n",
      "s3.ObjectSummary(bucket_name='awssampledbuswest2', key='tickit/spectrum/sales_partition/saledate=2008-03/0002_part_00')\n",
      "s3.ObjectSummary(bucket_name='awssampledbuswest2', key='tickit/spectrum/sales_partition/saledate=2008-03/0003_part_00')\n",
      "s3.ObjectSummary(bucket_name='awssampledbuswest2', key='tickit/spectrum/sales_partition/saledate=2008-03/0004_part_00')\n",
      "s3.ObjectSummary(bucket_name='awssampledbuswest2', key='tickit/spectrum/sales_partition/saledate=2008-03/0005_part_00')\n",
      "s3.ObjectSummary(bucket_name='awssampledbuswest2', key='tickit/spectrum/sales_partition/saledate=2008-04/0000_part_00')\n",
      "s3.ObjectSummary(bucket_name='awssampledbuswest2', key='tickit/spectrum/sales_partition/saledate=2008-04/0001_part_00')\n",
      "s3.ObjectSummary(bucket_name='awssampledbuswest2', key='tickit/spectrum/sales_partition/saledate=2008-04/0002_part_00')\n",
      "s3.ObjectSummary(bucket_name='awssampledbuswest2', key='tickit/spectrum/sales_partition/saledate=2008-04/0003_part_00')\n",
      "s3.ObjectSummary(bucket_name='awssampledbuswest2', key='tickit/spectrum/sales_partition/saledate=2008-04/0004_part_00')\n",
      "s3.ObjectSummary(bucket_name='awssampledbuswest2', key='tickit/spectrum/sales_partition/saledate=2008-04/0005_part_00')\n",
      "s3.ObjectSummary(bucket_name='awssampledbuswest2', key='tickit/spectrum/sales_partition/saledate=2008-05/0000_part_00')\n",
      "s3.ObjectSummary(bucket_name='awssampledbuswest2', key='tickit/spectrum/sales_partition/saledate=2008-05/0001_part_00')\n",
      "s3.ObjectSummary(bucket_name='awssampledbuswest2', key='tickit/spectrum/sales_partition/saledate=2008-05/0002_part_00')\n",
      "s3.ObjectSummary(bucket_name='awssampledbuswest2', key='tickit/spectrum/sales_partition/saledate=2008-05/0003_part_00')\n",
      "s3.ObjectSummary(bucket_name='awssampledbuswest2', key='tickit/spectrum/sales_partition/saledate=2008-05/0004_part_00')\n",
      "s3.ObjectSummary(bucket_name='awssampledbuswest2', key='tickit/spectrum/sales_partition/saledate=2008-05/0005_part_00')\n",
      "s3.ObjectSummary(bucket_name='awssampledbuswest2', key='tickit/spectrum/sales_partition/saledate=2008-06/0000_part_00')\n",
      "s3.ObjectSummary(bucket_name='awssampledbuswest2', key='tickit/spectrum/sales_partition/saledate=2008-06/0001_part_00')\n",
      "s3.ObjectSummary(bucket_name='awssampledbuswest2', key='tickit/spectrum/sales_partition/saledate=2008-06/0002_part_00')\n",
      "s3.ObjectSummary(bucket_name='awssampledbuswest2', key='tickit/spectrum/sales_partition/saledate=2008-06/0003_part_00')\n",
      "s3.ObjectSummary(bucket_name='awssampledbuswest2', key='tickit/spectrum/sales_partition/saledate=2008-06/0004_part_00')\n",
      "s3.ObjectSummary(bucket_name='awssampledbuswest2', key='tickit/spectrum/sales_partition/saledate=2008-06/0005_part_00')\n",
      "s3.ObjectSummary(bucket_name='awssampledbuswest2', key='tickit/spectrum/sales_partition/saledate=2008-07/0000_part_00')\n",
      "s3.ObjectSummary(bucket_name='awssampledbuswest2', key='tickit/spectrum/sales_partition/saledate=2008-07/0001_part_00')\n",
      "s3.ObjectSummary(bucket_name='awssampledbuswest2', key='tickit/spectrum/sales_partition/saledate=2008-07/0002_part_00')\n",
      "s3.ObjectSummary(bucket_name='awssampledbuswest2', key='tickit/spectrum/sales_partition/saledate=2008-07/0003_part_00')\n",
      "s3.ObjectSummary(bucket_name='awssampledbuswest2', key='tickit/spectrum/sales_partition/saledate=2008-07/0004_part_00')\n",
      "s3.ObjectSummary(bucket_name='awssampledbuswest2', key='tickit/spectrum/sales_partition/saledate=2008-07/0005_part_00')\n",
      "s3.ObjectSummary(bucket_name='awssampledbuswest2', key='tickit/spectrum/sales_partition/saledate=2008-08/0000_part_00')\n",
      "s3.ObjectSummary(bucket_name='awssampledbuswest2', key='tickit/spectrum/sales_partition/saledate=2008-08/0001_part_00')\n",
      "s3.ObjectSummary(bucket_name='awssampledbuswest2', key='tickit/spectrum/sales_partition/saledate=2008-08/0002_part_00')\n",
      "s3.ObjectSummary(bucket_name='awssampledbuswest2', key='tickit/spectrum/sales_partition/saledate=2008-08/0003_part_00')\n",
      "s3.ObjectSummary(bucket_name='awssampledbuswest2', key='tickit/spectrum/sales_partition/saledate=2008-08/0004_part_00')\n",
      "s3.ObjectSummary(bucket_name='awssampledbuswest2', key='tickit/spectrum/sales_partition/saledate=2008-08/0005_part_00')\n",
      "s3.ObjectSummary(bucket_name='awssampledbuswest2', key='tickit/spectrum/sales_partition/saledate=2008-09/0000_part_00')\n",
      "s3.ObjectSummary(bucket_name='awssampledbuswest2', key='tickit/spectrum/sales_partition/saledate=2008-09/0001_part_00')\n",
      "s3.ObjectSummary(bucket_name='awssampledbuswest2', key='tickit/spectrum/sales_partition/saledate=2008-09/0002_part_00')\n",
      "s3.ObjectSummary(bucket_name='awssampledbuswest2', key='tickit/spectrum/sales_partition/saledate=2008-09/0003_part_00')\n",
      "s3.ObjectSummary(bucket_name='awssampledbuswest2', key='tickit/spectrum/sales_partition/saledate=2008-09/0004_part_00')\n",
      "s3.ObjectSummary(bucket_name='awssampledbuswest2', key='tickit/spectrum/sales_partition/saledate=2008-09/0005_part_00')\n",
      "s3.ObjectSummary(bucket_name='awssampledbuswest2', key='tickit/spectrum/sales_partition/saledate=2008-10/0000_part_00')\n",
      "s3.ObjectSummary(bucket_name='awssampledbuswest2', key='tickit/spectrum/sales_partition/saledate=2008-10/0001_part_00')\n",
      "s3.ObjectSummary(bucket_name='awssampledbuswest2', key='tickit/spectrum/sales_partition/saledate=2008-10/0002_part_00')\n",
      "s3.ObjectSummary(bucket_name='awssampledbuswest2', key='tickit/spectrum/sales_partition/saledate=2008-10/0003_part_00')\n",
      "s3.ObjectSummary(bucket_name='awssampledbuswest2', key='tickit/spectrum/sales_partition/saledate=2008-10/0004_part_00')\n",
      "s3.ObjectSummary(bucket_name='awssampledbuswest2', key='tickit/spectrum/sales_partition/saledate=2008-10/0005_part_00')\n",
      "s3.ObjectSummary(bucket_name='awssampledbuswest2', key='tickit/spectrum/sales_partition/saledate=2008-11/0000_part_00')\n",
      "s3.ObjectSummary(bucket_name='awssampledbuswest2', key='tickit/spectrum/sales_partition/saledate=2008-11/0001_part_00')\n",
      "s3.ObjectSummary(bucket_name='awssampledbuswest2', key='tickit/spectrum/sales_partition/saledate=2008-11/0002_part_00')\n",
      "s3.ObjectSummary(bucket_name='awssampledbuswest2', key='tickit/spectrum/sales_partition/saledate=2008-11/0003_part_00')\n",
      "s3.ObjectSummary(bucket_name='awssampledbuswest2', key='tickit/spectrum/sales_partition/saledate=2008-11/0004_part_00')\n",
      "s3.ObjectSummary(bucket_name='awssampledbuswest2', key='tickit/spectrum/sales_partition/saledate=2008-11/0005_part_00')\n",
      "s3.ObjectSummary(bucket_name='awssampledbuswest2', key='tickit/spectrum/sales_partition/saledate=2008-12/0000_part_00')\n",
      "s3.ObjectSummary(bucket_name='awssampledbuswest2', key='tickit/spectrum/sales_partition/saledate=2008-12/0001_part_00')\n",
      "s3.ObjectSummary(bucket_name='awssampledbuswest2', key='tickit/spectrum/sales_partition/saledate=2008-12/0002_part_00')\n",
      "s3.ObjectSummary(bucket_name='awssampledbuswest2', key='tickit/spectrum/sales_partition/saledate=2008-12/0003_part_00')\n",
      "s3.ObjectSummary(bucket_name='awssampledbuswest2', key='tickit/spectrum/sales_partition/saledate=2008-12/0004_part_00')\n",
      "s3.ObjectSummary(bucket_name='awssampledbuswest2', key='tickit/spectrum/sales_partition/saledate=2008-12/0005_part_00')\n",
      "s3.ObjectSummary(bucket_name='awssampledbuswest2', key='tickit/spectrum/salesevent/')\n",
      "s3.ObjectSummary(bucket_name='awssampledbuswest2', key='tickit/spectrum/salesevent/salesmonth=2008-01/event=101/000')\n",
      "s3.ObjectSummary(bucket_name='awssampledbuswest2', key='tickit/spectrum/salesevent/salesmonth=2008-01/event=102/000')\n",
      "s3.ObjectSummary(bucket_name='awssampledbuswest2', key='tickit/spectrum/salesevent/salesmonth=2008-01/event=103/000')\n",
      "s3.ObjectSummary(bucket_name='awssampledbuswest2', key='tickit/spectrum/salesevent/salesmonth=2008-02/event=101/0000_part_00')\n",
      "s3.ObjectSummary(bucket_name='awssampledbuswest2', key='tickit/spectrum/salesevent/salesmonth=2008-02/event=101/0001_part_00')\n",
      "s3.ObjectSummary(bucket_name='awssampledbuswest2', key='tickit/spectrum/salesevent/salesmonth=2008-02/event=102/0000_part_00')\n",
      "s3.ObjectSummary(bucket_name='awssampledbuswest2', key='tickit/spectrum/salesevent/salesmonth=2008-02/event=102/0001_part_00')\n",
      "s3.ObjectSummary(bucket_name='awssampledbuswest2', key='tickit/spectrum/salesevent/salesmonth=2008-02/event=103/0000_part_00')\n",
      "s3.ObjectSummary(bucket_name='awssampledbuswest2', key='tickit/spectrum/salesevent/salesmonth=2008-02/event=103/0001_part_00')\n",
      "s3.ObjectSummary(bucket_name='awssampledbuswest2', key='tickit/spectrum/salesevent/salesmonth=2008-03/event=101/0000_part_00')\n",
      "s3.ObjectSummary(bucket_name='awssampledbuswest2', key='tickit/spectrum/salesevent/salesmonth=2008-03/event=101/0001_part_00')\n",
      "s3.ObjectSummary(bucket_name='awssampledbuswest2', key='tickit/spectrum/salesevent/salesmonth=2008-03/event=102/0000_part_00')\n",
      "s3.ObjectSummary(bucket_name='awssampledbuswest2', key='tickit/spectrum/salesevent/salesmonth=2008-03/event=102/0001_part_00')\n",
      "s3.ObjectSummary(bucket_name='awssampledbuswest2', key='tickit/spectrum/salesevent/salesmonth=2008-03/event=103/0000_part_00')\n",
      "s3.ObjectSummary(bucket_name='awssampledbuswest2', key='tickit/spectrum/salesevent/salesmonth=2008-03/event=103/0001_part_00')\n",
      "s3.ObjectSummary(bucket_name='awssampledbuswest2', key='tickit/spectrum/users/allusers_pipe.txt')\n",
      "s3.ObjectSummary(bucket_name='awssampledbuswest2', key='tickit/spectrum/venue/venue_pipe.txt')\n",
      "s3.ObjectSummary(bucket_name='awssampledbuswest2', key='tickit/svl_s3query.txt')\n",
      "s3.ObjectSummary(bucket_name='awssampledbuswest2', key='tickit/venue_pipe.txt')\n"
     ]
    }
   ],
   "source": [
    "for obj in sampleDbBucket.objects.all():\n",
    "    print(obj)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "toc-hr-collapsed": true
   },
   "source": [
    "# STEP 1: IAM ROLE\n",
    "- Create an IAM Role that makes Redshift able to access S3 bucket (ReadOnly)\n",
    "\n",
    "`dwhRole = iam.create_role(...)`\n",
    "- 这段代码非常重要，它在AWS中设置了Redshift所需的IAM角色权限\n",
    "- 这部分代码创建了一个IAM角色，让Redshift可以代表你访问其他AWS服务\n",
    "- 这很重要因为：没有这个角色，Redshift将无法读取S3中的数据\n",
    "\n",
    "\n",
    "`iam.attach_role_policy(...)`\n",
    "- 给角色添加了AmazonS3ReadOnlyAccess策略\n",
    "- 这让Redshift集群能够读取S3存储桶中的数据\n",
    "- 这很重要因为：如果没有这个权限，你的Redshift将无法从S3加载数据进行分析\n",
    "\n",
    "`roleArn = iam.get_role(...)['Role']['Arn']`\n",
    "- 获取角色的Amazon资源名称（ARN）,这个ARN在创建Redshift集群时需要用到\n",
    "- ARN (Amazon Resource Name) 是AWS中用来唯一标识资源的一个标识符\n",
    "- 身份证号码 - 用来唯一标识一个人\n",
    "- 手机号码 - 用来唯一联系一个人\n",
    "- ARN - 用来唯一标识AWS中的一个资源。如果不提供，就像给你一个手机，但不告诉你SIM卡号，你就无法打电话一样"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.1 Creating a new IAM Role\n",
      "An error occurred (EntityAlreadyExists) when calling the CreateRole operation: Role with name dwhRole already exists.\n",
      "1.2 Attaching Policy\n",
      "1.3 Get the IAM role ARN\n",
      "arn:aws:iam::339713039693:role/dwhRole\n"
     ]
    }
   ],
   "source": [
    "from botocore.exceptions import ClientError\n",
    "\n",
    "#1.1 Create the role, \n",
    "try:\n",
    "    print(\"1.1 Creating a new IAM Role\") \n",
    "    dwhRole = iam.create_role(\n",
    "        Path='/',\n",
    "        RoleName=DWH_IAM_ROLE_NAME,\n",
    "        Description = \"Allows Redshift clusters to call AWS services on your behalf.\",\n",
    "        AssumeRolePolicyDocument=json.dumps(\n",
    "            {'Statement': [{'Action': 'sts:AssumeRole',\n",
    "               'Effect': 'Allow',\n",
    "               'Principal': {'Service': 'redshift.amazonaws.com'}}],\n",
    "             'Version': '2012-10-17'})\n",
    "    )    \n",
    "except Exception as e:\n",
    "    print(e)\n",
    "    \n",
    "    \n",
    "print(\"1.2 Attaching Policy\")\n",
    "\n",
    "iam.attach_role_policy(RoleName=DWH_IAM_ROLE_NAME,\n",
    "                       PolicyArn=\"arn:aws:iam::aws:policy/AmazonS3ReadOnlyAccess\"\n",
    "                      )['ResponseMetadata']['HTTPStatusCode']\n",
    "\n",
    "print(\"1.3 Get the IAM role ARN\")\n",
    "roleArn = iam.get_role(RoleName=DWH_IAM_ROLE_NAME)['Role']['Arn']\n",
    "\n",
    "print(roleArn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# STEP 2:  Redshift Cluster\n",
    "\n",
    "- Create a [RedShift Cluster](https://console.aws.amazon.com/redshiftv2/home)\n",
    "- For complete arguments to `create_cluster`, see [docs](https://boto3.amazonaws.com/v1/documentation/api/latest/reference/services/redshift.html#Redshift.Client.create_cluster)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    response = redshift.create_cluster(        \n",
    "        #HW\n",
    "        ClusterType=DWH_CLUSTER_TYPE,\n",
    "        NodeType=DWH_NODE_TYPE,\n",
    "        NumberOfNodes=int(DWH_NUM_NODES),\n",
    "\n",
    "        #Identifiers & Credentials\n",
    "        DBName=DWH_DB,\n",
    "        ClusterIdentifier=DWH_CLUSTER_IDENTIFIER,\n",
    "        MasterUsername=DWH_DB_USER,\n",
    "        MasterUserPassword=DWH_DB_PASSWORD,\n",
    "        \n",
    "        #Roles (for s3 access)\n",
    "        IamRoles=[roleArn],\n",
    "\n",
    "        #Public Access\n",
    "\n",
    "        PubliclyAccessible=True\n",
    "    )\n",
    "except Exception as e:\n",
    "    print(e)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "toc-hr-collapsed": true
   },
   "source": [
    "## 2.1 *Describe* the cluster to see its status\n",
    "- run this block several times until the cluster status becomes `Available`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Key</th>\n",
       "      <th>Value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ClusterIdentifier</td>\n",
       "      <td>dwhclustertry4extra</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>NodeType</td>\n",
       "      <td>dc2.large</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ClusterStatus</td>\n",
       "      <td>available</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>MasterUsername</td>\n",
       "      <td>dwhuser</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>DBName</td>\n",
       "      <td>dwh</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Endpoint</td>\n",
       "      <td>{'Address': 'dwhclustertry4extra.czgl7wspitsl.us-west-2.redshift.amazonaws.com', 'Port': 5439}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>VpcId</td>\n",
       "      <td>vpc-08df3248a3b917e72</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>NumberOfNodes</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 Key  \\\n",
       "0  ClusterIdentifier   \n",
       "1           NodeType   \n",
       "2      ClusterStatus   \n",
       "3     MasterUsername   \n",
       "4             DBName   \n",
       "5           Endpoint   \n",
       "6              VpcId   \n",
       "7      NumberOfNodes   \n",
       "\n",
       "                                                                                            Value  \n",
       "0                                                                             dwhclustertry4extra  \n",
       "1                                                                                       dc2.large  \n",
       "2                                                                                       available  \n",
       "3                                                                                         dwhuser  \n",
       "4                                                                                             dwh  \n",
       "5  {'Address': 'dwhclustertry4extra.czgl7wspitsl.us-west-2.redshift.amazonaws.com', 'Port': 5439}  \n",
       "6                                                                           vpc-08df3248a3b917e72  \n",
       "7                                                                                               8  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def prettyRedshiftProps(props):\n",
    "    pd.set_option('display.max_colwidth', None)\n",
    "    keysToShow = [\"ClusterIdentifier\", \"NodeType\", \"ClusterStatus\", \"MasterUsername\", \"DBName\", \"Endpoint\", \"NumberOfNodes\", 'VpcId']\n",
    "    x = [(k, v) for k,v in props.items() if k in keysToShow]\n",
    "    return pd.DataFrame(data=x, columns=[\"Key\", \"Value\"])\n",
    "\n",
    "myClusterProps = redshift.describe_clusters(ClusterIdentifier=DWH_CLUSTER_IDENTIFIER)['Clusters'][0]\n",
    "prettyRedshiftProps(myClusterProps)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "toc-hr-collapsed": true
   },
   "source": [
    "<h2> 2.2 Take note of the cluster <font color='red'> endpoint and role ARN </font> </h2>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color='red'>DO NOT RUN THIS unless the cluster status becomes \"Available\". Make ure you are checking your Amazon Redshift cluster in the **us-west-2** region. </font>\n",
    "\n",
    "这段代码是从Redshift集群属性中提取两个重要的连接信息：\n",
    "- DWH_ENDPOINT：这是Redshift集群的访问地址，用于后续连接数据库。就像是数据仓库的\"门牌号码\"\n",
    "- DWH_ROLE_ARN：这是之前我们创建的IAM角色的ARN，用于验证权限设置是否正确"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DWH_ENDPOINT ::  dwhclustertry4extra.czgl7wspitsl.us-west-2.redshift.amazonaws.com\n",
      "DWH_ROLE_ARN ::  arn:aws:iam::339713039693:role/dwhRole\n"
     ]
    }
   ],
   "source": [
    "DWH_ENDPOINT = myClusterProps['Endpoint']['Address']\n",
    "DWH_ROLE_ARN = myClusterProps['IamRoles'][0]['IamRoleArn']\n",
    "print(\"DWH_ENDPOINT :: \", DWH_ENDPOINT)\n",
    "print(\"DWH_ROLE_ARN :: \", DWH_ROLE_ARN)  # 用于检查的目的\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "这里arn和之前redshift的arn am.get_role(RoleName=DWH_IAM_ROLE_NAME)['Role']['Arn'] 是一回事吗"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "是的，这是同一个ARN！让我解释一下这两处代码获取ARN的不同方式：\n",
    "\n",
    "1. 创建角色时获取ARN：\n",
    "```python\n",
    "roleArn = iam.get_role(RoleName=DWH_IAM_ROLE_NAME)['Role']['Arn']\n",
    "```\n",
    "- 这是从IAM服务直接获取刚创建的角色的ARN\n",
    "- 这是在创建Redshift集群之前获取的\n",
    "\n",
    "2. 从Redshift集群属性中获取ARN：\n",
    "```python\n",
    "DWH_ROLE_ARN = myClusterProps['IamRoles'][0]['IamRoleArn']\n",
    "```\n",
    "- 这是从已经运行的Redshift集群的属性中获取同一个ARN\n",
    "- 这是确认Redshift集群确实在使用我们之前创建的那个角色\n",
    "\n",
    "这就像是：\n",
    "1. 第一次是：\"我创建了一个钥匙，它的编号是xxx\"\n",
    "2. 第二次是：\"让我检查一下我的仓库用的是不是编号xxx的钥匙\"\n",
    "\n",
    "这两个值应该是完全相同的，只是获取的途径不同：\n",
    "- 一个是从\"钥匙管理处\"（IAM）获取\n",
    "- 一个是从\"仓库\"（Redshift）查看使用的钥匙编号\n",
    "\n",
    "这样做的目的是为了验证权限配置是否正确，确保Redshift确实在使用我们指定的IAM角色。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## STEP 3: Open an incoming  TCP port to access the cluster ednpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ec2.SecurityGroup(id='sg-089332983f4a97320')\n",
      "An error occurred (InvalidPermission.Duplicate) when calling the AuthorizeSecurityGroupIngress operation: the specified rule \"peer: 0.0.0.0/0, TCP, from port: 5439, to port: 5439, ALLOW\" already exists\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    vpc = ec2.Vpc(id=myClusterProps['VpcId'])\n",
    "    defaultSg = list(vpc.security_groups.all())[0]\n",
    "    print(defaultSg)\n",
    "    defaultSg.authorize_ingress(\n",
    "        GroupName=defaultSg.group_name,\n",
    "        CidrIp='0.0.0.0/0',\n",
    "        IpProtocol='TCP',\n",
    "        FromPort=int(DWH_PORT),\n",
    "        ToPort=int(DWH_PORT)\n",
    "    )\n",
    "except Exception as e:\n",
    "    print(e)\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "这段代码是在配置AWS安全组(Security Group)，让外部可以访问Redshift集群。让我详细解释：\n",
    "\n",
    "1. 获取VPC和安全组：\n",
    "```python\n",
    "vpc = ec2.Vpc(id=myClusterProps['VpcId'])  # 获取VPC\n",
    "defaultSg = list(vpc.security_groups.all())[0]  # 获取默认安全组\n",
    "```\n",
    "- 从Redshift集群属性中获取VPC ID\n",
    "- 找到这个VPC的默认安全组\n",
    "\n",
    "2. 配置入站规则：\n",
    "```python\n",
    "defaultSg.authorize_ingress(\n",
    "    GroupName=defaultSg.group_name,\n",
    "    CidrIp='0.0.0.0/0',        # 允许所有IP地址访问\n",
    "    IpProtocol='TCP',          # 使用TCP协议\n",
    "    FromPort=int(DWH_PORT),    # 开始端口(5439)\n",
    "    ToPort=int(DWH_PORT)       # 结束端口(5439)\n",
    ")\n",
    "```\n",
    "\n",
    "这就像是配置防火墙规则：\n",
    "- `CidrIp='0.0.0.0/0'` - 允许任何IP地址访问（⚠️要小心使用）\n",
    "- `FromPort=ToPort=5439` - 只开放Redshift默认端口\n",
    "\n",
    "安全提示：\n",
    "- `0.0.0.0/0` 意味着对所有IP开放，在生产环境中应该限制为特定IP范围\n",
    "- 比如公司办公网络的IP范围: `'192.168.1.0/24'`\n",
    "\n",
    "这段代码的目的是：\n",
    "1. 让你能从本地电脑连接到Redshift\n",
    "2. 让其他工具（如BI工具）能连接到Redshift\n",
    "3. 但也要注意安全性，生产环境应该更严格地限制访问"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# STEP 4: Make sure you can connect to the cluster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('PostgreSQL 8.0.2 on i686-pc-linux-gnu, compiled by GCC gcc (GCC) 3.4.2 20041017 (Red Hat 3.4.2-6.fc3), Redshift 1.0.107351',)\n"
     ]
    }
   ],
   "source": [
    "import psycopg2\n",
    "\n",
    "try:\n",
    "    conn = psycopg2.connect(\n",
    "        dbname=DWH_DB,\n",
    "        user=DWH_DB_USER,\n",
    "        password=DWH_DB_PASSWORD,\n",
    "        host=DWH_ENDPOINT,\n",
    "        port=DWH_PORT\n",
    "    )\n",
    "    \n",
    "    cur = conn.cursor()\n",
    "    \n",
    "    # 测试查询\n",
    "    cur.execute(\"SELECT VERSION()\")\n",
    "    version = cur.fetchone()\n",
    "    print(version)\n",
    "    \n",
    "except Exception as e:\n",
    "    print(\"Error:\", e)\n",
    "finally:\n",
    "    if 'cur' in locals():\n",
    "        cur.close()\n",
    "    if 'conn' in locals():\n",
    "        conn.close()\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "先暂停，进入下一个lab\n",
    "\n",
    "# STEP 5: Clean up your resources"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b><font color='red'>DO NOT RUN THIS UNLESS YOU ARE SURE <br/> \n",
    "    We will be using these resources in the next exercises</span></b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Cluster': {'ClusterIdentifier': 'dwhcluster',\n",
       "  'NodeType': 'dc2.large',\n",
       "  'ClusterStatus': 'deleting',\n",
       "  'ClusterAvailabilityStatus': 'Modifying',\n",
       "  'MasterUsername': 'dwhuser',\n",
       "  'DBName': 'dwh',\n",
       "  'Endpoint': {'Address': 'dwhcluster.czgl7wspitsl.us-west-2.redshift.amazonaws.com',\n",
       "   'Port': 5439},\n",
       "  'ClusterCreateTime': datetime.datetime(2025, 2, 16, 4, 42, 18, 205000, tzinfo=tzutc()),\n",
       "  'AutomatedSnapshotRetentionPeriod': 1,\n",
       "  'ManualSnapshotRetentionPeriod': -1,\n",
       "  'ClusterSecurityGroups': [],\n",
       "  'VpcSecurityGroups': [{'VpcSecurityGroupId': 'sg-089332983f4a97320',\n",
       "    'Status': 'active'}],\n",
       "  'ClusterParameterGroups': [{'ParameterGroupName': 'default.redshift-2.0',\n",
       "    'ParameterApplyStatus': 'in-sync'}],\n",
       "  'ClusterSubnetGroupName': 'default',\n",
       "  'VpcId': 'vpc-08df3248a3b917e72',\n",
       "  'AvailabilityZone': 'us-west-2b',\n",
       "  'PreferredMaintenanceWindow': 'sun:10:30-sun:11:00',\n",
       "  'PendingModifiedValues': {},\n",
       "  'ClusterVersion': '1.0',\n",
       "  'AllowVersionUpgrade': True,\n",
       "  'NumberOfNodes': 4,\n",
       "  'PubliclyAccessible': True,\n",
       "  'Encrypted': True,\n",
       "  'Tags': [],\n",
       "  'KmsKeyId': 'AWS_OWNED_KMS_KEY',\n",
       "  'EnhancedVpcRouting': False,\n",
       "  'IamRoles': [{'IamRoleArn': 'arn:aws:iam::339713039693:role/dwhRole',\n",
       "    'ApplyStatus': 'in-sync'}],\n",
       "  'MaintenanceTrackName': 'current',\n",
       "  'DeferredMaintenanceWindows': [],\n",
       "  'NextMaintenanceWindowStartTime': datetime.datetime(2025, 2, 16, 10, 30, tzinfo=tzutc()),\n",
       "  'ClusterNamespaceArn': 'arn:aws:redshift:us-west-2:339713039693:namespace:cfb19188-9fb9-4377-8a60-1f0c5fb5e539',\n",
       "  'TotalStorageCapacityInMegaBytes': 1600000,\n",
       "  'AquaConfiguration': {'AquaStatus': 'disabled',\n",
       "   'AquaConfigurationStatus': 'auto'},\n",
       "  'MultiAZ': 'Disabled'},\n",
       " 'ResponseMetadata': {'RequestId': '62efe910-be57-42ad-b2cf-3ab80ab10c11',\n",
       "  'HTTPStatusCode': 200,\n",
       "  'HTTPHeaders': {'x-amzn-requestid': '62efe910-be57-42ad-b2cf-3ab80ab10c11',\n",
       "   'content-type': 'text/xml',\n",
       "   'content-length': '2926',\n",
       "   'date': 'Sun, 16 Feb 2025 06:51:55 GMT'},\n",
       "  'RetryAttempts': 0}}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#### CAREFUL!!\n",
    "#-- Uncomment & run to delete the created resources\n",
    "redshift.delete_cluster( ClusterIdentifier=DWH_CLUSTER_IDENTIFIER,  SkipFinalClusterSnapshot=True)\n",
    "#### CAREFUL!!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- run this block several times until the cluster really deleted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'prettyRedshiftProps' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[8], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m myClusterProps \u001b[38;5;241m=\u001b[39m redshift\u001b[38;5;241m.\u001b[39mdescribe_clusters(ClusterIdentifier\u001b[38;5;241m=\u001b[39mDWH_CLUSTER_IDENTIFIER)[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mClusters\u001b[39m\u001b[38;5;124m'\u001b[39m][\u001b[38;5;241m0\u001b[39m]\n\u001b[0;32m----> 2\u001b[0m \u001b[43mprettyRedshiftProps\u001b[49m(myClusterProps)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'prettyRedshiftProps' is not defined"
     ]
    }
   ],
   "source": [
    "myClusterProps = redshift.describe_clusters(ClusterIdentifier=DWH_CLUSTER_IDENTIFIER)['Clusters'][0]\n",
    "prettyRedshiftProps(myClusterProps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'ResponseMetadata': {'RequestId': '276a033d-f7cc-4018-83a8-d48cea37a98e',\n",
       "  'HTTPStatusCode': 200,\n",
       "  'HTTPHeaders': {'date': 'Sun, 16 Feb 2025 06:52:12 GMT',\n",
       "   'x-amzn-requestid': '276a033d-f7cc-4018-83a8-d48cea37a98e',\n",
       "   'content-type': 'text/xml',\n",
       "   'content-length': '200'},\n",
       "  'RetryAttempts': 0}}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#### CAREFUL!!\n",
    "#-- Uncomment & run to delete the created resources\n",
    "iam.detach_role_policy(RoleName=DWH_IAM_ROLE_NAME, PolicyArn=\"arn:aws:iam::aws:policy/AmazonS3ReadOnlyAccess\")\n",
    "iam.delete_role(RoleName=DWH_IAM_ROLE_NAME)\n",
    "#### CAREFUL!!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Connection failed: could not translate host name \"dwhcluster.cjlk0pfgllo5.us-west-2.redshift.amazonaws.com\" to address: nodename nor servname provided, or not known\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import psycopg2\n",
    "\n",
    "try:\n",
    "    conn = psycopg2.connect(\n",
    "        host=\"dwhcluster.cjlk0pfgllo5.us-west-2.redshift.amazonaws.com\",\n",
    "        dbname=\"dwh\",\n",
    "        user=\"dwhuser\",\n",
    "        password=\"Passw0rd\",\n",
    "        port=5439\n",
    "    )\n",
    "    print(\"Connected successfully!\")\n",
    "except Exception as e:\n",
    "    print(\"Connection failed:\", e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "deleting\n",
      "{'Address': 'dwhcluster.czgl7wspitsl.us-west-2.redshift.amazonaws.com', 'Port': 5439}\n"
     ]
    }
   ],
   "source": [
    "# 打印集群状态\n",
    "print(redshift.describe_clusters(ClusterIdentifier=DWH_CLUSTER_IDENTIFIER)['Clusters'][0]['ClusterStatus'])\n",
    "\n",
    "# 确认endpoint\n",
    "print(redshift.describe_clusters(ClusterIdentifier=DWH_CLUSTER_IDENTIFIER)['Clusters'][0]['Endpoint'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current Security Group: sg-089b857887dc10194\n",
      "Security Group Error: An error occurred (InvalidPermission.Duplicate) when calling the AuthorizeSecurityGroupIngress operation: the specified rule \"peer: 0.0.0.0/0, TCP, from port: 5439, to port: 5439, ALLOW\" already exists\n"
     ]
    }
   ],
   "source": [
    "# 检查当前安全组规则\n",
    "try:\n",
    "    vpc = ec2.Vpc(id=myClusterProps['VpcId'])\n",
    "    defaultSg = list(vpc.security_groups.all())[0]\n",
    "    print(\"Current Security Group:\", defaultSg.id)\n",
    "    \n",
    "    # 重新设置入站规则\n",
    "    defaultSg.authorize_ingress(\n",
    "        GroupName=defaultSg.group_name,\n",
    "        CidrIp='0.0.0.0/0',  # 允许所有IP访问\n",
    "        IpProtocol='TCP',\n",
    "        FromPort=5439,\n",
    "        ToPort=5439\n",
    "    )\n",
    "except Exception as e:\n",
    "    print(\"Security Group Error:\", e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "ename": "ClusterNotFoundFault",
     "evalue": "An error occurred (ClusterNotFound) when calling the DescribeClusters operation: Cluster dwhcluster not found.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mClusterNotFoundFault\u001b[0m                      Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[12], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# 检查集群状态\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m response \u001b[38;5;241m=\u001b[39m \u001b[43mredshift\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdescribe_clusters\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m      3\u001b[0m \u001b[43m    \u001b[49m\u001b[43mClusterIdentifier\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mDWH_CLUSTER_IDENTIFIER\u001b[49m\n\u001b[1;32m      4\u001b[0m \u001b[43m)\u001b[49m\n\u001b[1;32m      5\u001b[0m cluster_status \u001b[38;5;241m=\u001b[39m response[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mClusters\u001b[39m\u001b[38;5;124m'\u001b[39m][\u001b[38;5;241m0\u001b[39m][\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mClusterStatus\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[1;32m      6\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCluster Status:\u001b[39m\u001b[38;5;124m\"\u001b[39m, cluster_status)\n",
      "File \u001b[0;32m~/Documents/GitHub/dl_cv/.venv/lib/python3.10/site-packages/botocore/client.py:569\u001b[0m, in \u001b[0;36mClientCreator._create_api_method.<locals>._api_call\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    565\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\n\u001b[1;32m    566\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mpy_operation_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m() only accepts keyword arguments.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    567\u001b[0m     )\n\u001b[1;32m    568\u001b[0m \u001b[38;5;66;03m# The \"self\" in this scope is referring to the BaseClient.\u001b[39;00m\n\u001b[0;32m--> 569\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_make_api_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43moperation_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Documents/GitHub/dl_cv/.venv/lib/python3.10/site-packages/botocore/client.py:1023\u001b[0m, in \u001b[0;36mBaseClient._make_api_call\u001b[0;34m(self, operation_name, api_params)\u001b[0m\n\u001b[1;32m   1019\u001b[0m     error_code \u001b[38;5;241m=\u001b[39m error_info\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mQueryErrorCode\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m error_info\u001b[38;5;241m.\u001b[39mget(\n\u001b[1;32m   1020\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCode\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1021\u001b[0m     )\n\u001b[1;32m   1022\u001b[0m     error_class \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mexceptions\u001b[38;5;241m.\u001b[39mfrom_code(error_code)\n\u001b[0;32m-> 1023\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m error_class(parsed_response, operation_name)\n\u001b[1;32m   1024\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1025\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m parsed_response\n",
      "\u001b[0;31mClusterNotFoundFault\u001b[0m: An error occurred (ClusterNotFound) when calling the DescribeClusters operation: Cluster dwhcluster not found."
     ]
    }
   ],
   "source": [
    "# 检查集群状态\n",
    "response = redshift.describe_clusters(\n",
    "    ClusterIdentifier=DWH_CLUSTER_IDENTIFIER\n",
    ")\n",
    "cluster_status = response['Clusters'][0]['ClusterStatus']\n",
    "print(\"Cluster Status:\", cluster_status)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "VPC ID: vpc-0ea59bc9b4003dc29\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "'Subnet'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[29], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# 打印VPC和子网信息\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mVPC ID:\u001b[39m\u001b[38;5;124m\"\u001b[39m, myClusterProps[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mVpcId\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[0;32m----> 3\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSubnet ID:\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[43mmyClusterProps\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mSubnet\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m)\n",
      "\u001b[0;31mKeyError\u001b[0m: 'Subnet'"
     ]
    }
   ],
   "source": [
    "# 打印VPC和子网信息\n",
    "print(\"VPC ID:\", myClusterProps['VpcId'])\n",
    "print(\"Subnet ID:\", myClusterProps['Subnet'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Endpoint: {'Address': 'dwhcluster.cjlk0pfgllo5.us-west-2.redshift.amazonaws.com', 'Port': 5439}\n",
      "VPC Security Groups: [{'VpcSecurityGroupId': 'sg-089b857887dc10194', 'Status': 'active'}]\n",
      "Availability Zone: us-west-2a\n",
      "Publicly Accessible: False\n"
     ]
    }
   ],
   "source": [
    "# 获取完整的集群信息\n",
    "response = redshift.describe_clusters(\n",
    "    ClusterIdentifier=DWH_CLUSTER_IDENTIFIER\n",
    ")\n",
    "cluster_info = response['Clusters'][0]\n",
    "\n",
    "# 打印关键信息\n",
    "print(\"Endpoint:\", cluster_info['Endpoint'])\n",
    "print(\"VPC Security Groups:\", cluster_info['VpcSecurityGroups'])\n",
    "print(\"Availability Zone:\", cluster_info['AvailabilityZone'])\n",
    "print(\"Publicly Accessible:\", cluster_info['PubliclyAccessible'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Modified cluster to be publicly accessible\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    response = redshift.modify_cluster(\n",
    "        ClusterIdentifier=DWH_CLUSTER_IDENTIFIER,\n",
    "        PubliclyAccessible=True\n",
    "    )\n",
    "    print(\"Modified cluster to be publicly accessible\")\n",
    "except Exception as e:\n",
    "    print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "toc-autonumbering": false,
  "toc-showcode": false,
  "toc-showmarkdowntxt": false,
  "toc-showtags": false
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
